# =============================================================================
# DOCSTREAM - Distributed RAG Ingestion Engine
# Environment Configuration Template
# =============================================================================

# -----------------------------------------------------------------------------
# GATEWAY SERVICE (Go)
# -----------------------------------------------------------------------------
API_GATEWAY_PORT=8080
JWT_SECRET=your-super-secret-jwt-key-change-this-in-production

# -----------------------------------------------------------------------------
# MINIO - S3-Compatible Object Storage
# -----------------------------------------------------------------------------
MINIO_ENDPOINT=localhost:9000
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin
MINIO_BUCKET_NAME=documents
MINIO_USE_SSL=false

# -----------------------------------------------------------------------------
# RABBITMQ - Message Broker
# -----------------------------------------------------------------------------
# Format: amqp://user:password@host:port/vhost
RABBITMQ_URL=amqp://guest:guest@localhost:5672/
RABBITMQ_HOST=localhost
RABBITMQ_PORT=5672
RABBITMQ_USER=guest
RABBITMQ_PASS=guest
RABBITMQ_QUEUE=ingestion_queue

# -----------------------------------------------------------------------------
# QDRANT - Vector Database
# -----------------------------------------------------------------------------
QDRANT_HOST=localhost
QDRANT_PORT=6333
COLLECTION_NAME=documents
QDRANT_API_KEY=  # Optional: leave empty for local dev

# -----------------------------------------------------------------------------
# INGESTION WORKER - AI Processing Configuration
# -----------------------------------------------------------------------------

# Vision Model Settings
MODEL_PATH=/app/models/Qwen2-VL-2B-Instruct-Q4_K_M.gguf
MMPROJ_PATH=/app/models/mmproj-Qwen2-VL-2B-Instruct-f16.gguf
USE_GPU=true  # Set to false for CPU-only inference

# Chunking Configuration
CHUNK_SIZE=512        # Target characters per chunk (256-1024 recommended)
CHUNK_OVERLAP=50      # Overlap between chunks (preserves context)

# Embedding Model (HuggingFace)
# Options:
#   - all-MiniLM-L6-v2 (384 dims, fast, good quality)
#   - all-mpnet-base-v2 (768 dims, slower, better quality)
EMBEDDING_MODEL=all-MiniLM-L6-v2

# Processing Options
PDF_DPI=150           # Image resolution for PDF conversion (100-300)
BATCH_SIZE=1          # PDFs to process simultaneously (adjust based on RAM)




